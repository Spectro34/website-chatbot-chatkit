# ğŸ¤– ChatKit - Containerized AI Chatbot

A production-ready, containerized AI chatbot that can be easily integrated into any website. Features local LLM support via Ollama with automatic OpenAI fallback.

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone and Setup
```bash
git clone https://github.com/yourusername/websitechatbot.git
cd websitechatbot
```

### 2. Configure Environment Variables
```bash
# Copy environment template
cp env.example .env

# Edit configuration
nano .env
```

**Required Configuration:**
```bash
# OpenAI API Key (for fallback)
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Server Configuration
NODE_ENV=production
PORT=3001

# Security Configuration
ALLOWED_ORIGINS=http://localhost:8080,https://yourdomain.com

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000
```

### 3. Deploy with Containerized Ollama (Recommended)
```bash
# Start Ollama container
cd ollama-setup
./setup.sh start
cd ..

# Deploy ChatKit with Ollama
./deploy.sh microservices-ollama
```

### 4. Access Your ChatBot
- **Website**: http://localhost:8080
- **API**: http://localhost:3001
- **Integration Example**: http://localhost:8080/examples/any-website-integration.html

## ğŸ—ï¸ Architecture

### Three-Container Setup
- **ğŸ§  Ollama Container**: Local LLM inference (llama2)
- **ğŸŒ Website Container**: Sample website with ChatKit widget
- **ğŸ¤– ChatBot Container**: Backend API with Ollama integration

### Container Communication
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Website       â”‚    â”‚   ChatBot       â”‚    â”‚   Ollama        â”‚
â”‚   (Port 8080)   â”‚â—„â”€â”€â–ºâ”‚   (Port 3001)   â”‚â—„â”€â”€â–ºâ”‚   (Port 11434)  â”‚
â”‚   Nginx + UI    â”‚    â”‚   Node.js API   â”‚    â”‚   LLM Engine    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ Configuration

### Environment Variables

#### For Containerized Deployment
```bash
# Copy environment template
cp env.example .env

# Edit with your settings
nano .env
```

**Required Variables:**
```bash
# OpenAI API Key (for fallback when Ollama is unavailable)
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Server Configuration
NODE_ENV=production
PORT=3001

# Security Configuration
ALLOWED_ORIGINS=http://localhost:8080,https://yourdomain.com

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000

# Session Configuration
SESSION_MAX_AGE_HOURS=24
```

#### For Ollama Setup
```bash
# Navigate to Ollama setup
cd ollama-setup

# Copy environment template
cp env.example .env

# Edit Ollama configuration
nano .env
```

**Ollama Variables:**
```bash
# Ollama Model Configuration
OLLAMA_MODEL=llama2        # Default model
# OLLAMA_MODEL=mistral     # Alternative model
# OLLAMA_MODEL=codellama   # Code-focused model
```

### Container Configuration

#### Docker Compose Environment
The containers automatically use environment variables from `.env`:

```yaml
# docker-compose.microservices-ollama.yml
services:
  chatbot-backend:
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OLLAMA_BASE_URL=http://ollama-server:11434
      - OLLAMA_MODEL=llama2:latest
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS}
```

#### Security Best Practices
```bash
# Never commit .env files to git
echo ".env" >> .gitignore

# Use strong, unique API keys
OPENAI_API_KEY=sk-proj-1234567890abcdef...

# Restrict allowed origins
ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# Set appropriate rate limits
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000
```

## ğŸ”§ Deployment Options

### Option 1: Containerized Ollama (Recommended)
```bash
./deploy.sh microservices-ollama
```
- Uses local Ollama container
- No external API costs
- Complete privacy

### Option 2: OpenAI Only
```bash
./deploy.sh microservices
```
- Uses OpenAI API
- Requires API key
- Faster responses

### Option 3: Local Development
```bash
./deploy.sh ollama
```
- Local development mode
- Optional Ollama support
- Hot reload enabled

## ğŸŒ Website Integration

### One-Line Integration
```html
<script src="http://localhost:8080/chatkit-widget.js"></script>
<script>
  ChatKit.init({
    apiUrl: 'http://localhost:3001',
    position: 'bottom-right'
  });
</script>
```

### Advanced Integration
```html
<script src="http://localhost:8080/chatkit-widget.js"></script>
<script>
  ChatKit.init({
    apiUrl: 'http://localhost:3001',
    position: 'bottom-right',
    theme: 'dark',
    welcomeMessage: 'Hello! How can I help you?',
    placeholder: 'Type your message...',
    onMessage: function(message) {
      console.log('User sent:', message);
    }
  });
</script>
```

## ğŸ¨ Customization

### Chat Interface Design
- **Position**: `bottom-right`, `bottom-left`, `top-right`, `top-left`
- **Theme**: `light`, `dark`, `auto`
- **Colors**: Custom CSS variables
- **Size**: Responsive design
- **Animation**: Smooth transitions

### Backend Configuration
- **Model**: Change Ollama model in `ollama-setup/.env`
- **API**: Modify endpoints in `backend/server-ollama.js`
- **Security**: Configure in `backend/security.js`
- **Rate Limiting**: Adjust in environment variables

## ğŸ“š Documentation

- **[Configuration Guide](CONFIGURATION_GUIDE.md)** - Complete setup and configuration
- **[Architecture Guide](ARCHITECTURE_DOCUMENTATION.md)** - Technical details
- **[Security Guide](SECURITY_GUIDE.md)** - Security features
- **[Deployment Guide](DEPLOYMENT_GUIDE.md)** - Production deployment
- **[Ollama Setup](ollama-setup/README.md)** - Local LLM setup

## ğŸ› ï¸ Development

### Project Structure
```
websitechatbot/
â”œâ”€â”€ backend/                 # ChatBot API
â”œâ”€â”€ sample-website/         # Demo website
â”œâ”€â”€ ollama-setup/          # Ollama container setup
â”œâ”€â”€ examples/              # Integration examples
â”œâ”€â”€ chatkit-widget.js      # Universal widget
â””â”€â”€ deploy.sh             # Deployment script
```

### Key Files
- `chatkit-widget.js` - Universal JavaScript widget
- `backend/server-ollama.js` - Ollama-compatible backend
- `docker-compose.microservices-ollama.yml` - Container orchestration
- `ollama-setup/setup.sh` - Ollama management

## ğŸ”’ Security Features

- âœ… API key protection
- âœ… Rate limiting
- âœ… Input sanitization
- âœ… CORS protection
- âœ… Session management
- âœ… Security headers

## ğŸš€ Production Ready

- âœ… Containerized deployment
- âœ… Health checks
- âœ… Logging
- âœ… Error handling
- âœ… Scalable architecture
- âœ… Easy integration

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/websitechatbot/issues)
- **Documentation**: See docs/ folder
- **Examples**: See examples/ folder