# ğŸ¤– ChatKit - Containerized AI Chatbot

A production-ready, containerized AI chatbot that can be easily integrated into any website. Features local LLM support via Ollama with automatic OpenAI fallback.

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone and Setup
```bash
git clone https://github.com/yourusername/websitechatbot.git
cd websitechatbot
```

### 2. Deploy with Containerized Ollama (Recommended)
```bash
# Start Ollama container
cd ollama-setup
./setup.sh start
cd ..

# Deploy ChatKit with Ollama
./deploy.sh microservices-ollama
```

### 3. Access Your ChatBot
- **Website**: http://localhost:8080
- **API**: http://localhost:3001
- **Integration Example**: http://localhost:8080/examples/any-website-integration.html

## ğŸ—ï¸ Architecture

### Three-Container Setup
- **ğŸ§  Ollama Container**: Local LLM inference (llama2)
- **ğŸŒ Website Container**: Sample website with ChatKit widget
- **ğŸ¤– ChatBot Container**: Backend API with Ollama integration

### Container Communication
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Website       â”‚    â”‚   ChatBot       â”‚    â”‚   Ollama        â”‚
â”‚   (Port 8080)   â”‚â—„â”€â”€â–ºâ”‚   (Port 3001)   â”‚â—„â”€â”€â–ºâ”‚   (Port 11434)  â”‚
â”‚   Nginx + UI    â”‚    â”‚   Node.js API   â”‚    â”‚   LLM Engine    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Deployment Options

### Option 1: Containerized Ollama (Recommended)
```bash
./deploy.sh microservices-ollama
```
- Uses local Ollama container
- No external API costs
- Complete privacy

### Option 2: OpenAI Only
```bash
./deploy.sh microservices
```
- Uses OpenAI API
- Requires API key
- Faster responses

### Option 3: Local Development
```bash
./deploy.sh ollama
```
- Local development mode
- Optional Ollama support
- Hot reload enabled

## ğŸŒ Website Integration

### One-Line Integration
```html
<script src="http://localhost:8080/chatkit-widget.js"></script>
<script>
  ChatKit.init({
    apiUrl: 'http://localhost:3001',
    position: 'bottom-right'
  });
</script>
```

### Advanced Integration
```html
<script src="http://localhost:8080/chatkit-widget.js"></script>
<script>
  ChatKit.init({
    apiUrl: 'http://localhost:3001',
    position: 'bottom-right',
    theme: 'dark',
    welcomeMessage: 'Hello! How can I help you?',
    placeholder: 'Type your message...',
    onMessage: function(message) {
      console.log('User sent:', message);
    }
  });
</script>
```

## ğŸ¨ Customization

### Chat Interface Design
- **Position**: `bottom-right`, `bottom-left`, `top-right`, `top-left`
- **Theme**: `light`, `dark`, `auto`
- **Colors**: Custom CSS variables
- **Size**: Responsive design
- **Animation**: Smooth transitions

### Backend Configuration
- **Model**: Change Ollama model in `ollama-setup/.env`
- **API**: Modify endpoints in `backend/server-ollama.js`
- **Security**: Configure in `backend/security.js`
- **Rate Limiting**: Adjust in environment variables

## ğŸ“š Documentation

- **[Architecture Guide](ARCHITECTURE_DOCUMENTATION.md)** - Technical details
- **[Security Guide](SECURITY_GUIDE.md)** - Security features
- **[Deployment Guide](DEPLOYMENT_GUIDE.md)** - Production deployment
- **[Ollama Setup](ollama-setup/README.md)** - Local LLM setup

## ğŸ› ï¸ Development

### Project Structure
```
websitechatbot/
â”œâ”€â”€ backend/                 # ChatBot API
â”œâ”€â”€ sample-website/         # Demo website
â”œâ”€â”€ ollama-setup/          # Ollama container setup
â”œâ”€â”€ examples/              # Integration examples
â”œâ”€â”€ chatkit-widget.js      # Universal widget
â””â”€â”€ deploy.sh             # Deployment script
```

### Key Files
- `chatkit-widget.js` - Universal JavaScript widget
- `backend/server-ollama.js` - Ollama-compatible backend
- `docker-compose.microservices-ollama.yml` - Container orchestration
- `ollama-setup/setup.sh` - Ollama management

## ğŸ”’ Security Features

- âœ… API key protection
- âœ… Rate limiting
- âœ… Input sanitization
- âœ… CORS protection
- âœ… Session management
- âœ… Security headers

## ğŸš€ Production Ready

- âœ… Containerized deployment
- âœ… Health checks
- âœ… Logging
- âœ… Error handling
- âœ… Scalable architecture
- âœ… Easy integration

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/websitechatbot/issues)
- **Documentation**: See docs/ folder
- **Examples**: See examples/ folder