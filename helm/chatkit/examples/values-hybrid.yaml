# Example: Hybrid deployment (Ollama primary, OpenAI fallback)
# This configuration uses Ollama as primary and OpenAI as fallback

# Enable both Ollama and OpenAI
ollama:
  enabled: true
  model: "llama2:latest"
  resources:
    limits:
      cpu: 4000m
      memory: 8Gi
    requests:
      cpu: 2000m
      memory: 4Gi
  persistence:
    enabled: true
    size: 50Gi

openai:
  enabled: true
  apiKey: "sk-proj-your-openai-api-key-here"
  model: "gpt-3.5-turbo"
  maxTokens: 500
  temperature: 0.7

# Deployment type configuration
deploymentType:
  type: "hybrid"
  hybrid:
    primaryProvider: "ollama"
    fallbackProvider: "openai"
    fallbackThreshold: 10

# Backend configuration
backend:
  enabled: true
  replicaCount: 2
  env:
    NODE_ENV: "production"
    PORT: 3001
    ALLOWED_ORIGINS: "https://yourdomain.com"
    MAX_REQUESTS_PER_MINUTE: 60
    MAX_REQUESTS_PER_HOUR: 1000

# Frontend configuration
frontend:
  enabled: true
  replicaCount: 2
  widget:
    theme: "light"
    position: "bottom-right"
    autoOpen: false

# Ingress configuration
ingress:
  enabled: true
  hosts:
    - host: chatkit.yourdomain.com
      paths:
        - path: /
          pathType: Prefix
          service: frontend
        - path: /api
          pathType: Prefix
          service: backend
